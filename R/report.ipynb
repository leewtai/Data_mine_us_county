{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59643434-70c6-4b39-bfcb-a51a5aaae691",
   "metadata": {},
   "source": [
    "I think that the student's project is exploring the Social Vulnerability Index by comparing the number of married and unmarried households from different counties and states in a temporal pattern for 14 years (2008  to 2022). The student first calculates the recent change in household counts by fitting a best-fit curve to the household counts to find an implied slope and taking a second derivative to find the acceleration. However, they are only interested in the slope and acceleration for 2022 alone. They scaled and centered the curve data before assigning the 2022 curve cases with R2 values less than 0.6 with a value of -1 and the others with a value of 1. Afterwards, they use k-means clustering to find their optimal k value. Finally, they use random forest to predict the cluster classes and cross-validate to find their predictive errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb74260-0411-4338-ba6b-4f43b939b3fe",
   "metadata": {},
   "source": [
    "Non-technical improvement: I recommend looking at the problem that the ML is trying to solve. We want a meaningful or valuable solution or conclusion. Based on the conclusion, the ML did not improve its predictions. It performed worse than randomly guessing. The factors correlated to the change in household counts turned out to be unsurprising. With this revelation, changing our Y values from household curves to more impactful ones like the SVI scores is better. In addition, it would be more holistic to see if the ML model is able to classify communities that are more susceptible to economic disasters based on the SVI.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12224a98-e68b-4b6d-a327-206b8586cbc5",
   "metadata": {},
   "source": [
    "Technical Improvement (Please see updated cluster.R code): I dealt with the missing values with column means before I scaled the features to deal with imbalanced data. Afterwards, I applied PCA to explain the 90% variance. I did this so it could improve the recall and precision of the student's random forest model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
